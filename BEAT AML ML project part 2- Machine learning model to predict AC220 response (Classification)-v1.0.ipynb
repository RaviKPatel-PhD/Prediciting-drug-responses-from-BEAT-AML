{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beat AML ML project part 2- Machine learning model to predict AC220 response\n",
    "\n",
    "**SPOILER ALERT: This notebook made me realize that I could not build an accurate classifier, If you want to skip to the next notebook (Part 3) you will not miss anything.**\n",
    "\n",
    "**Background:** This is the second notebook of the series. If you have not already done so please visit the first notebook for background information on the project and the general plan. In that first notebook we obtained a dataset which contain clinical information, genetic information (mutations), gene expression information and drug sensitivity information of over 400 Acute Myeloid Leukemia (AML) tumor biopsies. This information came from the recent [BEAT AML publication by Tyner et al in Nature](https://www.nature.com/articles/s41586-018-0623-z). We cleaned and combined the clinical, genetic and gene expression datasets into one data set, which will form our features. We are trying to predict whether or not patients will respond to a given therapy with this information. Then for those patients that do respond, we are trying to undertsnad the extent of their response. We can achieve this by stacking two models. First a classifier to catogorize patients into responders and non-responders, then a regressor to predict the extent of response. Tyner et al. tested 112 different therapies against these 400+ patients. This means we will have to solve 112 classifcation and regression problems. **Here I will focus on making a classifier/regressor, and interpreting that classifier, for just one treatment.** Specifically we will try to differentiate the patients that respond from those that do not respond at all.\n",
    "\n",
    "**Information abour AC220:** I would like to justify why I chose AC220 as my example case in this notebook. AC220 is of personal interest to me, because I work with it in my day job as an AML researcher. AC220 is also known as Quizartinib. It is currently uner investigation in clinical trials to determine its efficacy either alone or in combination with chemotherapy. The reason why AC220 is so interesting is because it was specifically meant to treat one subset of AML patients, those that have the internal tandem duplication (ITD) mutation in a gene called Flt3. Without getting into too much detail, when Flt3 is mutated with an ITD it is always in an 'on' state which tells the cell to proliferate, divide and grow. Basically Flt3-ITD drive the cancer phenotype. AC220 is one treatment that is meant to turn Flt3-ITD off. The interesting thing is, from the currently published clinical data, we know that not all patients with Flt3-ITD respond to AC220. Also some patients that don't have Flt3-ITD also respond to AC220. It would be really interesting if we could figure out what features determine AC220 sensitivity. \n",
    "\n",
    "## Imports and datasets\n",
    "\n",
    "Lets import our packages and load the dataframes from the previous notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['font.size'] = 24\n",
    "import seaborn as sns\n",
    "sns.set(font_scale = 2)\n",
    "\n",
    "# No warnings about setting value on copy of slice\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# Imputing missing values and scaling values\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#Import train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import Hyperparameter tuning\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "# Import Machine Learning models for Classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "# Import for scoring \n",
    "from sklearn.metrics import accuracy_score, make_scorer, confusion_matrix, f1_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CEBPA_Biallelic</th>\n",
       "      <th>isRelapse</th>\n",
       "      <th>isDenovo</th>\n",
       "      <th>isTransformed</th>\n",
       "      <th>priorMalignancyNonMyeloid</th>\n",
       "      <th>cumulativeChemo</th>\n",
       "      <th>priorMalignancyRadiationTx</th>\n",
       "      <th>priorMDS</th>\n",
       "      <th>priorMDSMoreThanTwoMths</th>\n",
       "      <th>priorMDSMPN</th>\n",
       "      <th>...</th>\n",
       "      <th>GALNT7exp</th>\n",
       "      <th>C1RLexp</th>\n",
       "      <th>HLA-Fexp</th>\n",
       "      <th>EIF4A1exp</th>\n",
       "      <th>NARFexp</th>\n",
       "      <th>YPEL2exp</th>\n",
       "      <th>BTN3A2exp</th>\n",
       "      <th>TUBB6exp</th>\n",
       "      <th>MAT2Bexp</th>\n",
       "      <th>AP1S2exp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13-00098</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>59.160975</td>\n",
       "      <td>33.539380</td>\n",
       "      <td>42.109566</td>\n",
       "      <td>225.642033</td>\n",
       "      <td>59.516830</td>\n",
       "      <td>52.488684</td>\n",
       "      <td>45.252956</td>\n",
       "      <td>12.514251</td>\n",
       "      <td>41.190273</td>\n",
       "      <td>49.849423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13-00118</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>135.493625</td>\n",
       "      <td>90.068184</td>\n",
       "      <td>39.047906</td>\n",
       "      <td>97.924147</td>\n",
       "      <td>61.485233</td>\n",
       "      <td>66.065462</td>\n",
       "      <td>100.272240</td>\n",
       "      <td>75.834686</td>\n",
       "      <td>101.344825</td>\n",
       "      <td>65.949507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13-00149</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>138.230096</td>\n",
       "      <td>31.928819</td>\n",
       "      <td>28.304911</td>\n",
       "      <td>56.609823</td>\n",
       "      <td>87.111042</td>\n",
       "      <td>38.051025</td>\n",
       "      <td>86.946318</td>\n",
       "      <td>0.576531</td>\n",
       "      <td>134.798366</td>\n",
       "      <td>61.084799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13-00157</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>148.073938</td>\n",
       "      <td>56.587364</td>\n",
       "      <td>45.798333</td>\n",
       "      <td>36.605639</td>\n",
       "      <td>53.229553</td>\n",
       "      <td>65.091982</td>\n",
       "      <td>77.092026</td>\n",
       "      <td>118.982088</td>\n",
       "      <td>137.229861</td>\n",
       "      <td>135.193157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13-00160</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.502231</td>\n",
       "      <td>62.321038</td>\n",
       "      <td>68.885714</td>\n",
       "      <td>58.648291</td>\n",
       "      <td>88.001355</td>\n",
       "      <td>43.725944</td>\n",
       "      <td>19.954300</td>\n",
       "      <td>39.185618</td>\n",
       "      <td>51.216037</td>\n",
       "      <td>60.585882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2687 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          CEBPA_Biallelic  isRelapse  isDenovo  isTransformed  \\\n",
       "LabId                                                           \n",
       "13-00098                0          0         1              0   \n",
       "13-00118                0          1         0              0   \n",
       "13-00149                0          0         0              0   \n",
       "13-00157                0          0         1              0   \n",
       "13-00160                0          0         0              1   \n",
       "\n",
       "          priorMalignancyNonMyeloid  cumulativeChemo  \\\n",
       "LabId                                                  \n",
       "13-00098                          0                1   \n",
       "13-00118                          0                1   \n",
       "13-00149                          1                1   \n",
       "13-00157                          0                1   \n",
       "13-00160                          0                1   \n",
       "\n",
       "          priorMalignancyRadiationTx  priorMDS  priorMDSMoreThanTwoMths  \\\n",
       "LabId                                                                     \n",
       "13-00098                           0         0                        0   \n",
       "13-00118                           0         0                        0   \n",
       "13-00149                           0         0                        0   \n",
       "13-00157                           0         0                        0   \n",
       "13-00160                           0         1                        1   \n",
       "\n",
       "          priorMDSMPN     ...       GALNT7exp    C1RLexp   HLA-Fexp  \\\n",
       "LabId                     ...                                         \n",
       "13-00098            0     ...       59.160975  33.539380  42.109566   \n",
       "13-00118            0     ...      135.493625  90.068184  39.047906   \n",
       "13-00149            0     ...      138.230096  31.928819  28.304911   \n",
       "13-00157            0     ...      148.073938  56.587364  45.798333   \n",
       "13-00160            0     ...       27.502231  62.321038  68.885714   \n",
       "\n",
       "           EIF4A1exp    NARFexp   YPEL2exp   BTN3A2exp    TUBB6exp  \\\n",
       "LabId                                                                \n",
       "13-00098  225.642033  59.516830  52.488684   45.252956   12.514251   \n",
       "13-00118   97.924147  61.485233  66.065462  100.272240   75.834686   \n",
       "13-00149   56.609823  87.111042  38.051025   86.946318    0.576531   \n",
       "13-00157   36.605639  53.229553  65.091982   77.092026  118.982088   \n",
       "13-00160   58.648291  88.001355  43.725944   19.954300   39.185618   \n",
       "\n",
       "            MAT2Bexp    AP1S2exp  \n",
       "LabId                             \n",
       "13-00098   41.190273   49.849423  \n",
       "13-00118  101.344825   65.949507  \n",
       "13-00149  134.798366   61.084799  \n",
       "13-00157  137.229861  135.193157  \n",
       "13-00160   51.216037   60.585882  \n",
       "\n",
       "[5 rows x 2687 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reload the Target and Features dataframes\n",
    "\n",
    "Features = pd.read_csv('Features.csv')\n",
    "Features.set_index('LabId', inplace=True)\n",
    "\n",
    "Targets = pd.read_csv('Targets.csv')\n",
    "Targets.set_index('LabId', inplace=True)\n",
    "\n",
    "Features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape the Target and Features datasets\n",
    "\n",
    "Next, lets pull out only the AC220 data from our Targets dataset, convert the IC<sub>50</sub> values to a yes/no classification and merge it to the Features dataset. All non-responders were labeled with 10 as the IC<sub>50</sub> values. I will assume any label higher than 8 is a non reponder.\n",
    "\n",
    "We can use our function from the last workbook to get the AC220 data from Targets. We can define a function to make our labels (1 for responders and 0 for non responders). We can then merge the labels column to the features dataset to make our final dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(247,) (247, 2687)\n"
     ]
    }
   ],
   "source": [
    "# Define the function for pulling out AC220 data\n",
    "def Get_Target (dataset, compound, measurement = 'ic50'):\n",
    "    Target = dataset[dataset['inhibitor'].str.contains(compound)]\n",
    "    Target = Target[measurement]\n",
    "    return Target\n",
    "\n",
    "# Define the function for making the labels (If doing classification)\n",
    "def make_label (data, threshold):\n",
    "    bins = [0, threshold, 10]\n",
    "    labels = [0,1]    \n",
    "    label = pd.cut(data, bins = bins, labels = labels)\n",
    "    return label\n",
    "\n",
    "# Run function to pull out AC220 IC50 values and make the labels (Classification)\n",
    "Target = make_label(Get_Target(Targets, 'AC220'), 2)\n",
    "\n",
    "# Keep only the rows of Target and Features that are in both dataframes (both)\n",
    "idx = Target.index.intersection(Features.index)\n",
    "Target = Target.loc[idx]\n",
    "Features = Features.loc[idx]\n",
    "\n",
    "# Find the shape of the new dataframes\n",
    "print(Target.shape, Features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay now we have our target and features datasets. Unfortunately it looks like there was a lot less overlapp between the Taget an Features datasets. This is probably due to limited sample from each patient. Hopefully 247 samples is still enough that we can learn something!\n",
    "\n",
    "Lets count how many responder we have in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n"
     ]
    }
   ],
   "source": [
    "# Count the number of non-reponders\n",
    "count = 0\n",
    "for i in Target:\n",
    "    if i == 1: count = count +1\n",
    "    else: continue\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have 204 patients that are responders. This means our dataset is skewed to include mostly responder, even though we know that only ~50% of patients actually respond (see first notebook). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into training, test and validation datasets\n",
    "\n",
    "Now lets split our data into training, test and validation data sets. We will use sklearn's Train_test_split here.\n",
    "\n",
    "If you are not familiar, The training set is what we will use to optimize and train our model, while the test set is what we can use to test the model on untrained data. I opt to keep the test size small (20%) because we have such a small dataset, it would be a shame to lose more of it to testing. The validation set is untouched by the model, while optimizing the model for the test set, because our dataset is so small and it is unlikely that this model will be deployed in the real world, I decided to forgo the validation set.\n",
    "\n",
    "The random_state parameter allows us to reproducibly get the same split (if we keep the parameter unchanged. The convention in the machine learning field is to name your features with a capital X and targets with a lowercase y, which is what I will do here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(197, 2687)\n",
      "(197,)\n",
      "(50, 2687)\n",
      "(50,)\n"
     ]
    }
   ],
   "source": [
    "# Split the remaining data into 80% training and 20% testing set\n",
    "X, X_test, y, y_test = train_test_split(Features, Target, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Find out the shape of the datasets\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling the features\n",
    "\n",
    "The final step to take before building the models is scaling the features. Some types of machine learning models do not require scaling (i.e. linear regression and random forest). In general I prefer to always scale the data, because we can always reverse the scaling (back transform) after we make our prediction if we have to.\n",
    "\n",
    "Here we will apply a normalization to scale our data. For a given feature's normalization, the minimum value is subtracted from all data point and then all values are divided by the largest data point. **Using a standardization rather than a normalization could potentially improve the model.** This results in the largest value being set to 1 and the smallest value set to 0. We can easily do this using sklean MinMaxScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a scaler object with a range of 0-1\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Fit to the training data\n",
    "scaler.fit(X)\n",
    "\n",
    "# Transform both the training and testing data with the scaler\n",
    "X = scaler.transform(X)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "#Then lets convert y to a one dimensional array so we can use it for machine learning\n",
    "y = np.array(y).reshape((-1, ))\n",
    "y_test = np.array(y_test).reshape((-1, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning- Classification\n",
    "\n",
    "Okay now we can try to make a classifier. Lets try out some of SKlearn's classifiers. I will try all of the following using mostly default options:\n",
    "1. Logistic Regression\n",
    "2. Multi-Layer Perceptron (Neural Net)\n",
    "3. K-nearest neighbors\n",
    "4. support vector classifier (Both linear and radial basis function)\n",
    "5. Gaussian process classifier\n",
    "6. Decision Tree\n",
    "7. Random Forest Classifier\n",
    "8. Ada boost Classifier\n",
    "9. Gaussian Naive Bayes \n",
    "10. Quadratic Discrimination Analysis\n",
    "\n",
    "We can then pick the best performing ones and work on hyper-parameter tuning those before we settle on the best performing classifier. The function below will return both the test and training scores. This will allow us to see accuracy, but also check for overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Logistic Regression classifier has an training accuracy score of 0.7157360406091371 and test score of 0.78.\n",
      "The MLPClassifier classifier has an training accuracy score of 0.7157360406091371 and test score of 0.78.\n",
      "The KNeighborsClassifier classifier has an training accuracy score of 0.8274111675126904 and test score of 0.7.\n",
      "The SVC linear classifier has an training accuracy score of 0.9289340101522843 and test score of 0.78.\n",
      "The SVC rbf classifier has an training accuracy score of 1.0 and test score of 0.78.\n",
      "The GaussianProcessClassifier classifier has an training accuracy score of 1.0 and test score of 0.66.\n",
      "The DecisionTreeClassifier classifier has an training accuracy score of 0.9543147208121827 and test score of 0.72.\n",
      "The RandomForestClassifier classifier has an training accuracy score of 0.8426395939086294 and test score of 0.8.\n",
      "The AdaBoostClassifier classifier has an training accuracy score of 1.0 and test score of 0.76.\n",
      "The GaussianNB classifier has an training accuracy score of 0.7157360406091371 and test score of 0.66.\n",
      "The QuadraticDiscriminantAnalysis classifier has an training accuracy score of 1.0 and test score of 0.5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "# Make a funtion to fit and score a model.\n",
    "def fit_and_score(clf):\n",
    "    clf.fit(X,y)\n",
    "    return clf.score(X_test, y_test), clf.score(X,y)\n",
    "\n",
    "# Logistic Regression\n",
    "LR_clf, LR_clf2 = fit_and_score(LogisticRegression(C = 0.0001))\n",
    "\n",
    "# MLPClassifier\n",
    "MLP_clf, MLP_clf2 = fit_and_score(MLPClassifier(alpha=1))\n",
    "\n",
    "# KNeighborsClassifier\n",
    "KNN_clf, KNN_clf2 = fit_and_score(KNeighborsClassifier(3))\n",
    "\n",
    "# SVC Linear\n",
    "SVM_lin_clf, SVM_lin_clf2 = fit_and_score(SVC(kernel=\"linear\", C=0.025))\n",
    "\n",
    "# SVC rbf\n",
    "SVM_clf, SVM_clf2 = fit_and_score(SVC(gamma=2, C=1))\n",
    "\n",
    "# GaussianProcessClassifier\n",
    "GausP_clf, GausP_clf2 = fit_and_score(GaussianProcessClassifier(1.0 * RBF(1.0)))\n",
    "\n",
    "# DecisionTreeClassifier\n",
    "DTC_clf, DTC_clf2 = fit_and_score(DecisionTreeClassifier(max_depth=5))\n",
    "\n",
    "# RandomForestClassifier\n",
    "RF_clf, RF_clf2 = fit_and_score(RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1))\n",
    "\n",
    "# AdaBoostClassifier\n",
    "AB_clf, AB_clf2 = fit_and_score(AdaBoostClassifier())\n",
    "\n",
    "# GaussianNB\n",
    "GNB_clf, GNB_clf2 = fit_and_score(GaussianNB())\n",
    "\n",
    "# QuadraticDiscriminantAnalysis\n",
    "Quad_clf, Quad_clf2 = fit_and_score(QuadraticDiscriminantAnalysis())\n",
    "\n",
    "Classifiers = ['Logistic Regression', 'MLPClassifier', 'KNeighborsClassifier', 'SVC linear', 'SVC rbf', \n",
    "               'GaussianProcessClassifier', 'DecisionTreeClassifier', 'RandomForestClassifier', 'AdaBoostClassifier', \n",
    "               'GaussianNB', 'QuadraticDiscriminantAnalysis']\n",
    "Test_accuracies = [LR_clf, MLP_clf, KNN_clf, SVM_lin_clf, SVM_clf, GausP_clf, DTC_clf, RF_clf, AB_clf, GNB_clf, Quad_clf]\n",
    "Train_accuracies = [LR_clf2, MLP_clf2, KNN_clf2, SVM_lin_clf2, SVM_clf2, GausP_clf2, DTC_clf2, RF_clf2, AB_clf2, GNB_clf2, \n",
    "                   Quad_clf2]\n",
    "\n",
    "for clf, train, test in zip(Classifiers, Train_accuracies, Test_accuracies):\n",
    "    print('The {0} classifier has an training accuracy score of {1} and test score of {2}.'.format(clf, train, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's focus on using the Logistic regression, Support vector, KNN and Random forest classifiers. These all have a score of at least 0.8 while not overfitting too much.\n",
    "\n",
    "\n",
    "## Hyperparameter tuning\n",
    "\n",
    "Here I will use GridSearchCV to find the best set of parameters. We will optimize for the best scoring parameters., we can then print the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Penalty: l2\n",
      "Best C: 1.0\n",
      "Train score: 1.0\n",
      "Test score: 0.76\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning for logistic regression\n",
    "# Modified this code from https://chrisalbon.com/machine_learning/model_selection/hyperparameter_tuning_using_grid_search/\n",
    "\n",
    "# Create logistic regression\n",
    "logistic = LogisticRegression()\n",
    "\n",
    "# Create regularization penalty space\n",
    "penalty = ['l1', 'l2']\n",
    "\n",
    "# Create regularization hyperparameter space\n",
    "C = np.logspace(0, 4, 10)\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(C=C, penalty=penalty)\n",
    "\n",
    "# Function to maximize\n",
    "_score = make_scorer(accuracy_score, greater_is_better=True)\n",
    "\n",
    "# Create grid search using 5-fold cross validation\n",
    "clf = GridSearchCV(logistic, hyperparameters, cv=5, verbose=0, scoring='accuracy')\n",
    "\n",
    "# Fit grid search\n",
    "best_model = clf.fit(X, y)\n",
    "\n",
    "# View best hyperparameters and train/test score\n",
    "print('Best Penalty:', best_model.best_estimator_.get_params()['penalty'])\n",
    "print('Best C:', best_model.best_estimator_.get_params()['C'])\n",
    "print('Train score:', clf.score(X, y))\n",
    "print('Test score:', clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best kernel: poly\n",
      "Best C: 0.012742749857031322\n",
      "Best gamma: 0.02069138081114788\n",
      "Train score: 0.949238578680203\n",
      "Test score: 0.8\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning for support vector classifier\n",
    "\n",
    "# Create SVC\n",
    "from sklearn.svm import SVC\n",
    "SVC = SVC()\n",
    "\n",
    "# Create kernal space\n",
    "kernel = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "\n",
    "# Create regularization hyperparameter space\n",
    "C = np.logspace(-10, 4, 20)\n",
    "\n",
    "gamma = np.logspace(-5, 4, 20)\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(C=C, kernel=kernel, gamma=gamma)\n",
    "\n",
    "# Function to maximize\n",
    "#_score = make_scorer(accuracy_score, greater_is_better=True)\n",
    "\n",
    "# Create grid search using 5-fold cross validation\n",
    "clf = GridSearchCV(SVC, hyperparameters, cv=5, verbose=0, scoring = 'accuracy')\n",
    "\n",
    "# Fit grid search\n",
    "best_model = clf.fit(X, y)\n",
    "\n",
    "# View best hyperparameters and train/test score\n",
    "print('Best kernel:', best_model.best_estimator_.get_params()['kernel'])\n",
    "print('Best C:', best_model.best_estimator_.get_params()['C'])\n",
    "print('Best gamma:', best_model.best_estimator_.get_params()['gamma'])\n",
    "print('Train score:', clf.score(X, y))\n",
    "print('Test score:', clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best n_neighbors: 1\n",
      "Best weights: uniform\n",
      "Best algorithm: ball_tree\n",
      "Best leaf_size: 1\n",
      "Train score: 1.0\n",
      "Test score: 0.62\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning for KNeighbors classifier\n",
    "\n",
    "# Create KNN\n",
    "KNN = KNeighborsClassifier()\n",
    "\n",
    "# Create Number neighbors space\n",
    "n_neighbors = [1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "# Create regularization hyperparameter space\n",
    "weights = ['uniform', 'distance']\n",
    "algorithm = ['ball_tree', 'kd_tree', 'brute']\n",
    "leaf_size= [1,5,10,25,50,100]\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(n_neighbors = n_neighbors, weights=weights, algorithm=algorithm, leaf_size= leaf_size)\n",
    "\n",
    "# Function to maximize\n",
    "#_score = make_scorer(accuracy_score, greater_is_better=True)\n",
    "\n",
    "# Create grid search using 5-fold cross validation\n",
    "clf = GridSearchCV(KNN, hyperparameters, cv=5, verbose=0, scoring ='accuracy')\n",
    "\n",
    "# Fit grid search\n",
    "best_model = clf.fit(X, y)\n",
    "\n",
    "# View best hyperparameters and train/test score\n",
    "print('Best n_neighbors:', best_model.best_estimator_.get_params()['n_neighbors'])\n",
    "print('Best weights:', best_model.best_estimator_.get_params()['weights'])\n",
    "print('Best algorithm:', best_model.best_estimator_.get_params()['algorithm'])\n",
    "print('Best leaf_size:', best_model.best_estimator_.get_params()['leaf_size'])\n",
    "print('Train score:', clf.score(X, y))\n",
    "print('Test score:', clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best max_depth: 10\n",
      "Best n_estimators: 60\n",
      "Best max_features: 8\n",
      "Train score: 1.0\n",
      "Test score: 0.82\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning for Random Forest Classifier\n",
    "\n",
    "# Create Random forest classifier\n",
    "RFC = RandomForestClassifier()\n",
    "\n",
    "# Create max depth space\n",
    "max_depth = np.linspace(1,10,10).astype(int)\n",
    "\n",
    "# Create N-estimators space\n",
    "n_estimators = np.linspace(5,500,10).astype(int)\n",
    "\n",
    "# Create max features space\n",
    "max_features = [1,2,4,8,12,24]\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(max_depth=max_depth, n_estimators=n_estimators, max_features=max_features)\n",
    "\n",
    "# Function to maximize\n",
    "#_score = make_scorer(accuracy_score, greater_is_better=True)\n",
    "\n",
    "# Create grid search using 5-fold cross validation\n",
    "clf = GridSearchCV(RFC, hyperparameters, cv=5, verbose=0, scoring ='accuracy')\n",
    "\n",
    "# Fit grid search\n",
    "best_model = clf.fit(X, y)\n",
    "\n",
    "# View best hyperparameters and train/test score\n",
    "print('Best max_depth:', best_model.best_estimator_.get_params()['max_depth'])\n",
    "print('Best n_estimators:', best_model.best_estimator_.get_params()['n_estimators'])\n",
    "print('Best max_features:', best_model.best_estimator_.get_params()['max_features'])\n",
    "print('Train score:', clf.score(X, y))\n",
    "print('Test score:', clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking a closer look at the best classifiers\n",
    "\n",
    "It seems that Gridsearch did not help improve our models too much. We only achieved modest improvements in each classifier. This limitation on model accuracy probably has to do with the fact that our dataset is small and that the number of responders is only ~20% of the dataset. Because our data is highly skewed to mostly include responders, it is possible that the model could just always classify as a responder and still have 80% accuracy. Lets take a look at the confusion matrix for each model and make sure they are accurately prediciting some of the non-responders in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.76\n",
      "[[32  7]\n",
      " [ 5  6]]\n",
      "[[141   0]\n",
      " [  0  56]]\n",
      "0.4999999999999999\n"
     ]
    }
   ],
   "source": [
    "#logistic\n",
    "logistic = LogisticRegression(penalty='l2', C=1, solver='lbfgs')\n",
    "logistic.fit(X,y)\n",
    "print(logistic.score(X,y))\n",
    "print(logistic.score(X_test,y_test))\n",
    "print(confusion_matrix(y_test, logistic.predict(X_test)))\n",
    "print(confusion_matrix(y, logistic.predict(X)))\n",
    "print(f1_score(y_test, logistic.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9796954314720813\n",
      "0.76\n",
      "[[33  6]\n",
      " [ 6  5]]\n",
      "[[141   0]\n",
      " [  4  52]]\n",
      "0.45454545454545453\n"
     ]
    }
   ],
   "source": [
    "#SVC\n",
    "from sklearn.svm import SVC\n",
    "SVC = SVC(kernel=\"poly\", C=10000, gamma=0.00026366508987303583, degree=3)\n",
    "SVC.fit(X,y)\n",
    "print(SVC.score(X,y))\n",
    "print(SVC.score(X_test,y_test))\n",
    "print(confusion_matrix(y_test, SVC.predict(X_test)))\n",
    "print(confusion_matrix(y, SVC.predict(X)))\n",
    "print(f1_score(y_test, SVC.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7360406091370558\n",
      "0.82\n",
      "[[39  0]\n",
      " [ 9  2]]\n",
      "[[139   2]\n",
      " [ 50   6]]\n"
     ]
    }
   ],
   "source": [
    "#KNeighbors    \n",
    "KNN= KNeighborsClassifier(n_neighbors=6,weights='uniform',algorithm='ball_tree', leaf_size=1)\n",
    "KNN.fit(X,y)\n",
    "print(KNN.score(X,y))\n",
    "print(KNN.score(X_test,y_test))\n",
    "print(confusion_matrix(y_test, KNN.predict(X_test)))\n",
    "print(confusion_matrix(y, KNN.predict(X)))\n",
    "# print(f1_score(y_test, KNN.predict(X_test))) #F-1 metric doesn't really make sense for K-nearest neighbors classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7817258883248731\n",
      "0.82\n",
      "[[39  0]\n",
      " [ 9  2]]\n",
      "[[137   4]\n",
      " [ 39  17]]\n",
      "0.3076923076923077\n"
     ]
    }
   ],
   "source": [
    "#Random Forest   \n",
    "RFC = RandomForestClassifier(max_depth=3, n_estimators=5, max_features=8)\n",
    "RFC.fit(X,y)\n",
    "print(RFC.score(X,y))\n",
    "print(RFC.score(X_test,y_test))\n",
    "print(confusion_matrix(y_test, RFC.predict(X_test)))\n",
    "print(confusion_matrix(y, RFC.predict(X)))\n",
    "print(f1_score(y_test, RFC.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be honest none of the classifier are performig that great! K-nearest neighbors and Random Forest classifiers are basically always classifying everything as responders (as I suspected some classifiers might be). Logistic regression and the support vector classifier are at least making an attempt to predict some non-responders in the test data, but neither are doing a great job. I decided to move on witht the support vector classifier since it is less over-fit and slightly more accurate on the test data (And therefore slightly higher F-1 score). \n",
    "\n",
    "Okay now lets save our best classifier and then we can focus on using regression to predict the extent of response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_Classifier = SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting the SVC model\n",
    "\n",
    "The support vector classifier is a little bit harder to interpret than most of the classifiers sklearn has to offer. **Major caveat is that we know the classifier has some major flaws, so the interpretation can not be trusted anyway.** In fact the model can only give feature importances for the linear kernel as described in this [stack overflow post](https://stackoverflow.com/questions/41592661/determining-the-most-contributing-features-for-svm-classifier-in-sklearn).\n",
    "\n",
    "Therefore, we can't interpret this model much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "Unfortunately this attempt to make a classifier was not successful. I think this is mostly because of the small dataset size and the skewness towards responders. In the next notebook we will make a regression model that will help us determine the extent of response in those patients that do respond. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
